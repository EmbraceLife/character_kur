{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "- make a fluid/defaults splits as needed for each modification\n",
    "- Try different ways to reduce overfitting and divergence\n",
    "    - add dropout to each gru layer?\n",
    "    - learning rate?\n",
    "    - L2 ...\n",
    "- implement dlnd_character_example model in kur (make sure the model structure first)\n",
    "- How can I change directories inside `fluid.yml` rather than in `defaults.yml`?\n",
    "- it says people spend 30-40% time on gathering, cleaning and feature engineering dataset. Kur is taking care of them by defaults. Then the tasks to complete is to add more feature engineering features, right?\n",
    "\n",
    "**Keras/TL docs and tutorials + Kur experimentations**\n",
    "- At the moment tensorflow docs makes no sense to me\n",
    "- tensorflow docs present a huge knowledge gap between me and TF implementations\n",
    "- kur docs is encouragingly short, but not at all enough to fill my knowledge gap\n",
    "- I wonder would [keras](https://keras.io/layers/recurrent/) and [TL docs](http://tensorlayer.readthedocs.io/en/latest/modules/layers.html#fixed-length-recurrent-layer) or [TFLearn doc](http://tflearn.org/layers/recurrent/) provide more accessible knowledge for me to fill the gap presented by tensorflow?\n",
    "- then use Kur to implement Keras and TL tutorials\n",
    "\n",
    "**Kur experimentation features**\n",
    "- plot or print weights and activation of each layer\n",
    "- Here it can help me understand: what exact does **`output` layer** do, [kur doc](https://hyp.is/vrwiIAC4EeekgltPOmLV_Q/kur.deepgram.com/containers.html) does not make much sense for me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Natsume/Downloads/kur_road/character_rnn'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure you are at a level of directory with all the py files\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__pycache__\u001b[m\u001b[m/        cleaned.txt         \u001b[34mt1\u001b[m\u001b[m/                 vocab.py\r\n",
      "\u001b[34mbooks\u001b[m\u001b[m/              \u001b[34mdata\u001b[m\u001b[m/               view_data.py\r\n",
      "char_rnn_demo.yaml  make_data.py        view_logs.py\r\n",
      "char_rnn_kur.ipynb  steps.sh            view_outputs.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## **Create a small dataset for speed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "source": [
    "- inside `make_data.py` set `dev=True` to reduce data size by x10\n",
    "- make_data create a data file named cleaned.txt\n",
    "- It is nice we can control size of dataset, so I wonder is it possible to **use `provider` inside kurfile.yaml to control how much data to use**? \n",
    "\n",
    "**Effect of doing the above**\n",
    "- make_data.py only takes a few seconds\n",
    "- `kur -v train kurfile.yaml` only takes less than 4 mins, compared to default setting's estimated 5 hours training \n",
    "- Also the previous 30 minutes loading time is gone too\n",
    "- **What made it to take 30 mins to load previously**? was it the large dataset? with smaller dataset, loading time reduced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13300\n",
      "dims:\n",
      "(13300, 30, 30)\n",
      "(13300, 30)\n",
      "13300 14131\n",
      "dims:\n",
      "(831, 30, 30)\n",
      "(831, 30)\n",
      "14131 14962\n",
      "dims:\n",
      "(831, 30, 30)\n",
      "(831, 30)\n",
      "14962 15793\n",
      "dims:\n",
      "(831, 30, 30)\n",
      "(831, 30)\n",
      "CPU times: user 327 ms, sys: 108 ms, total: 436 ms\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python make_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Let's view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "peek at train:\n",
      "------\n",
      "\"the project gutenberg ebook of\" --> \" \"\n",
      "\"he project gutenberg ebook of \" --> \"p\"\n",
      "\"e project gutenberg ebook of p\" --> \"r\"\n",
      "------\n",
      "\"o particular resentment by his\" --> \" \"\n",
      "\" particular resentment by his \" --> \"h\"\n",
      "\"particular resentment by his h\" --> \"a\"\n",
      "\n",
      "\n",
      "peek at validate:\n",
      "------\n",
      "\"articular resentment by his ha\" --> \"v\"\n",
      "\"rticular resentment by his hav\" --> \"i\"\n",
      "\"ticular resentment by his havi\" --> \"n\"\n",
      "------\n",
      "\"ingley for a kingdom upon my h\" --> \"o\"\n",
      "\"ngley for a kingdom upon my ho\" --> \"n\"\n",
      "\"gley for a kingdom upon my hon\" --> \"o\"\n",
      "\n",
      "\n",
      "peek at test:\n",
      "------\n",
      "\"ley for a kingdom upon my hono\" --> \"u\"\n",
      "\"ey for a kingdom upon my honou\" --> \"r\"\n",
      "\"y for a kingdom upon my honour\" --> \" \"\n",
      "------\n",
      "\"sting your time with me. mr. b\" --> \"i\"\n",
      "\"ting your time with me. mr. bi\" --> \"n\"\n",
      "\"ing your time with me. mr. bin\" --> \"g\"\n",
      "\n",
      "\n",
      "peek at evaluate:\n",
      "------\n",
      "\"ng your time with me. mr. bing\" --> \"l\"\n",
      "\"g your time with me. mr. bingl\" --> \"e\"\n",
      "\" your time with me. mr. bingle\" --> \"y\"\n",
      "------\n",
      "\"they had yet learnt to care fo\" --> \"r\"\n",
      "\"hey had yet learnt to care for\" --> \" \"\n",
      "\"ey had yet learnt to care for \" --> \"a\"\n",
      "CPU times: user 92 ms, sys: 34.2 ms, total: 126 ms\n",
      "Wall time: 6.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python view_data.py\n",
    "# below is last bit of data from trainingset, validation set, test set, evaluation set\n",
    "# left part of --> is X or input\n",
    "# right part of --> is y or output\n",
    "\n",
    "## If needed, I shall dig into it to see more of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Let's see the kurfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%pycat char_rnn_demo.yaml\n",
    "# copy and paste kurfile.yaml before to see the kurfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting char_rnn_demo.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile char_rnn_demo.yaml\n",
    "\n",
    "---\n",
    "\n",
    "settings:\n",
    "\n",
    "  vocab:\n",
    "    size: 30\n",
    "\n",
    "  rnn:\n",
    "    size: 128\n",
    "    depth: 3\n",
    "\n",
    "model:\n",
    "  - input: in_seq\n",
    "\n",
    "  - for:\n",
    "      range: \"{{ rnn.depth - 1 }}\"\n",
    "      iterate:\n",
    "        - recurrent:\n",
    "            size: \"{{ rnn.size }}\"\n",
    "            type: gru\n",
    "            sequence: yes\n",
    "            bidirectional: no\n",
    "        - batch_normalization\n",
    "\n",
    "  - recurrent:\n",
    "      size: \"{{ rnn.size }}\"\n",
    "      type: gru\n",
    "      sequence: no\n",
    "      bidirectional: no\n",
    "\n",
    "  - dense: \"{{ vocab.size }}\"\n",
    "\n",
    "  - activation: softmax\n",
    "\n",
    "  - output: out_char\n",
    "\n",
    "loss:\n",
    "  - target: out_char\n",
    "    name: categorical_crossentropy\n",
    "\n",
    "train:\n",
    "  data:\n",
    "    - jsonl: data/train.jsonl\n",
    "  epochs: 5                                \n",
    "  weights:\n",
    "    initial: t1/best.w.kur\n",
    "    best: t1/best.w.kur\n",
    "    last: t1/last.w.kur\n",
    "  log: t1/log\n",
    "  hooks:                                   # Let plot loss\n",
    "    - plot: t1/loss.png\n",
    "\n",
    "\n",
    "validate:\n",
    "  data:\n",
    "    - jsonl: data/validate.jsonl\n",
    "  weights: t1/best.w.kur\n",
    "\n",
    "\n",
    "test:\n",
    "  data:\n",
    "    - jsonl: data/test.jsonl\n",
    "  weights: t1/best.w.kur\n",
    "\n",
    "\n",
    "evaluate:\n",
    "  data:\n",
    "    - jsonl: data/evaluate.jsonl\n",
    "  weights: t1/best.w.kur\n",
    "\n",
    "  destination: t1/output.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the model\n",
    "- data is created and stored inside data/ in the same level of model/\n",
    "- from the loss plot below, we see **overfitting and divergence**, what is the cause and how to reduce overfit and make better convergence? \n",
    "    - add drop out\n",
    "    - use LSTM instead of GRU\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__pycache__\u001b[m\u001b[m/        cleaned.txt         \u001b[34mt1\u001b[m\u001b[m/                 vocab.py\r\n",
      "\u001b[34mbooks\u001b[m\u001b[m/              \u001b[34mdata\u001b[m\u001b[m/               view_data.py\r\n",
      "char_rnn_demo.yaml  make_data.py        view_logs.py\r\n",
      "char_rnn_kur.ipynb  steps.sh            view_outputs.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-04 11:53:04,394 kur.kurfile:699]\u001b[0m Parsing source: char_rnn_demo.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:04,414 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:04,461 kur.loggers.binary_logger:71]\u001b[0m Loading log data: t1/log\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:09,869 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:09,870 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:09,870 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:11,181 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:11,182 kur.model.model:260]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:11,182 kur.model.model:265]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:11,182 kur.model.model:280]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:12,404 kur.model.model:284]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:12,405 kur.model.model:285]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:12,405 kur.kurfile:357]\u001b[0m Ignoring missing initial weights: t1/best.w.kur. If this is undesireable, set \"must_exist\" to \"yes\" in the approriate \"weights\" section.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:12,405 kur.model.executor:315]\u001b[0m No historical training loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:12,405 kur.model.executor:323]\u001b[0m No historical validation loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:12,405 kur.model.executor:329]\u001b[0m No previous epochs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:53:46,435 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\n",
      "Epoch 1/5, loss=2.296: 100%|████████| 13300/13300 [00:59<00:00, 224.86samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:54:45,973 kur.model.executor:464]\u001b[0m Training loss: 2.296\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:54:45,973 kur.model.executor:471]\u001b[0m Saving best historical training weights: t1/best.w.kur\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:54:49,540 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Validating, loss=1.898: 100%|██████████| 831/831 [00:00<00:00, 1262.65samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:54:50,220 kur.model.executor:197]\u001b[0m Validation loss: 1.898\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:54:50,220 kur.model.executor:413]\u001b[0m Saving best historical validation weights: t1/best.w.kur\u001b[0m\n",
      "\n",
      "Epoch 2/5, loss=1.769: 100%|████████| 13300/13300 [00:56<00:00, 234.65samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:55:47,512 kur.model.executor:464]\u001b[0m Training loss: 1.769\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:55:47,513 kur.model.executor:471]\u001b[0m Saving best historical training weights: t1/best.w.kur\u001b[0m\n",
      "Validating, loss=1.756: 100%|██████████| 831/831 [00:00<00:00, 1105.79samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:55:48,298 kur.model.executor:197]\u001b[0m Validation loss: 1.756\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:55:48,298 kur.model.executor:413]\u001b[0m Saving best historical validation weights: t1/best.w.kur\u001b[0m\n",
      "\n",
      "Epoch 3/5, loss=1.559: 100%|████████| 13300/13300 [00:55<00:00, 239.24samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:56:44,383 kur.model.executor:464]\u001b[0m Training loss: 1.559\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:56:44,383 kur.model.executor:471]\u001b[0m Saving best historical training weights: t1/best.w.kur\u001b[0m\n",
      "Validating, loss=1.658: 100%|██████████| 831/831 [00:00<00:00, 1163.20samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:56:45,135 kur.model.executor:197]\u001b[0m Validation loss: 1.658\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:56:45,135 kur.model.executor:413]\u001b[0m Saving best historical validation weights: t1/best.w.kur\u001b[0m\n",
      "\n",
      "Epoch 4/5, loss=1.396: 100%|████████| 13300/13300 [00:56<00:00, 236.41samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:57:41,983 kur.model.executor:464]\u001b[0m Training loss: 1.396\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:57:41,984 kur.model.executor:471]\u001b[0m Saving best historical training weights: t1/best.w.kur\u001b[0m\n",
      "Validating, loss=1.662: 100%|██████████| 831/831 [00:00<00:00, 1224.37samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:57:42,700 kur.model.executor:197]\u001b[0m Validation loss: 1.662\u001b[0m\n",
      "\n",
      "Epoch 5/5, loss=1.261: 100%|████████| 13300/13300 [00:56<00:00, 234.54samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:58:39,903 kur.model.executor:464]\u001b[0m Training loss: 1.261\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 11:58:39,903 kur.model.executor:471]\u001b[0m Saving best historical training weights: t1/best.w.kur\u001b[0m\n",
      "Validating, loss=1.680: 100%|██████████| 831/831 [00:00<00:00, 1098.57samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 11:58:40,694 kur.model.executor:197]\u001b[0m Validation loss: 1.680\u001b[0m\n",
      "Completed 5 epochs.\n",
      "\u001b[1;37m[INFO 2017-03-04 11:58:41,318 kur.model.executor:235]\u001b[0m Saving most recent weights: t1/last.w.kur\u001b[0m\n",
      "CPU times: user 6.64 s, sys: 1.8 s, total: 8.44 s\n",
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kur -v train char_rnn_demo.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAG0CAYAAAA7Go31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWv8fJWrIfJCj7O8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='t1/loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### split into 2 kurfiles for easy modify\n",
    "- give `epochs:` a default value and an overide value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting char_rnn_demo_defaults.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile char_rnn_demo_defaults.yaml\n",
    "\n",
    "---\n",
    "\n",
    "settings:\n",
    "\n",
    "  vocab:\n",
    "    size: 30\n",
    "\n",
    "  rnn:\n",
    "    size: 128\n",
    "    depth: 3\n",
    "\n",
    "model:\n",
    "  - input: in_seq\n",
    "\n",
    "  - for:\n",
    "      range: \"{{ rnn.depth - 1 }}\"\n",
    "      iterate:\n",
    "        - recurrent:\n",
    "            size: \"{{ rnn.size }}\"\n",
    "            type: gru\n",
    "            sequence: yes\n",
    "            bidirectional: no\n",
    "        - batch_normalization\n",
    "\n",
    "  - recurrent:\n",
    "      size: \"{{ rnn.size }}\"\n",
    "      type: gru\n",
    "      sequence: no\n",
    "      bidirectional: no\n",
    "\n",
    "  - dense: \"{{ vocab.size }}\"\n",
    "\n",
    "  - activation: softmax\n",
    "\n",
    "  - output: out_char\n",
    "\n",
    "loss:\n",
    "  - target: out_char\n",
    "    name: categorical_crossentropy\n",
    "\n",
    "train:\n",
    "  data:\n",
    "    - jsonl: data/train.jsonl\n",
    "  epochs: \"{{ num_epochs|default(5) }}\"     # add default and overide values\n",
    "  weights:\n",
    "    initial: t1/best.w.kur\n",
    "    best: t1/best.w.kur\n",
    "    last: t1/last.w.kur\n",
    "  log: t1/log\n",
    "  hooks:                                   # Let plot loss\n",
    "#     - plot: t1/loss.png\n",
    "    - plot:\n",
    "        loss_per_batch: t1/loss1.png\n",
    "        loss_per_time: t1/loss2.png\n",
    "        throughput_per_time: t1/loss3.png\n",
    "\n",
    "validate:\n",
    "  data:\n",
    "    - jsonl: data/validate.jsonl\n",
    "  weights: t1/best.w.kur\n",
    "\n",
    "\n",
    "test:\n",
    "  data:\n",
    "    - jsonl: data/test.jsonl\n",
    "  weights: t1/best.w.kur\n",
    "\n",
    "\n",
    "evaluate:\n",
    "  data:\n",
    "    - jsonl: data/evaluate.jsonl\n",
    "  weights: t1/best.w.kur\n",
    "\n",
    "  destination: t1/output.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting char_rrn_demo_fluid.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile char_rrn_demo_fluid.yaml\n",
    "\n",
    "---\n",
    "settings: \n",
    "  num_epochs: 1\n",
    "\n",
    "\n",
    "include: char_rnn_demo_defaults.yaml\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-04 15:30:31,648 kur.kurfile:699]\u001b[0m Parsing source: char_rrn_demo_fluid.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:31,651 kur.kurfile:699]\u001b[0m Parsing source: char_rnn_demo_defaults.yaml, included by char_rrn_demo_fluid.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:31,664 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:31,690 kur.loggers.binary_logger:71]\u001b[0m Loading log data: t1/log\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:35,732 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:35,732 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:35,732 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:36,877 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:36,877 kur.model.model:260]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:36,877 kur.model.model:265]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:36,878 kur.model.model:280]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:38,026 kur.model.model:284]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:38,026 kur.model.model:285]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:38,059 kur.model.executor:313]\u001b[0m Best historical training loss: 0.389\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:38,061 kur.model.executor:320]\u001b[0m Best historical validation loss: 1.658\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:38,061 kur.model.executor:331]\u001b[0m Restarting from epoch 21.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:30:58,854 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\n",
      "Epoch 21/21, loss=0.400: 100%|██████| 13300/13300 [00:41<00:00, 361.86samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 15:31:40,453 kur.model.executor:464]\u001b[0m Training loss: 0.400\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:31:42,695 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Validating, loss=2.647: 100%|██████████| 831/831 [00:00<00:00, 1563.78samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 15:31:43,240 kur.model.executor:197]\u001b[0m Validation loss: 2.647\u001b[0m\n",
      "Completed 21 epochs.\n",
      "\u001b[1;37m[INFO 2017-03-04 15:31:44,748 kur.model.executor:235]\u001b[0m Saving most recent weights: t1/last.w.kur\u001b[0m\n",
      "CPU times: user 1.52 s, sys: 1.78 s, total: 3.29 s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kur -v train char_rrn_demo_fluid.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**In average, it takes 6 minutes to run 5 epochs, compared with first 5 epochs 5:40 min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAG0CAYAAAA7Go31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIyIiIkNLgY6IiIgMrf8PT02odGtMhooAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='t1/loss1.png') # overfitting and divergence !!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAG0CAYAAAA7Go31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='t1/loss2.png') # overfitting and divergence !!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAG0CAYAAAAxRiOnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUWYaFYYURVEURZlpVBhSFEVRFGWm+f/84wvEHjgqxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='t1/loss3.png') # overfitting and divergence !!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate \n",
    "- what exactly is the purpose of evaluate?\n",
    "- is slightly **over 50% accuracy** is considered good result? How so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-04 12:56:11,235 kur.kurfile:699]\u001b[0m Parsing source: char_rnn_demo.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:11,253 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:11,550 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:11,550 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:11,551 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:13,434 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:13,435 kur.model.model:260]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:13,435 kur.model.model:265]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:13,435 kur.model.model:280]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:14,702 kur.model.model:284]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:14,703 kur.model.model:285]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:18,902 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Evaluating: 100%|███████████████████████| 831/831 [00:00<00:00, 987.50samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 12:56:19,827 kur.model.hooks.output_hook:40]\u001b[0m Saving model output as pickle: t1/output.pkl\u001b[0m\n",
      "CPU times: user 163 ms, sys: 57 ms, total: 220 ms\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kur -v evaluate char_rnn_demo.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%pycat view_outputs.py\n",
    "\n",
    "# we must get output.pkl into and from the correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting view_outputs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile view_outputs.py\n",
    "\n",
    "\"\"\"\n",
    "Copyright 2016 Deepgram\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import view_data\n",
    "from vocab import *\n",
    "\n",
    "\n",
    "if len(sys.argv) < 2:\n",
    "    pickle_fname = 't1/output.pkl'\n",
    "else:\n",
    "    pickle_fname = sys.argv[1]\n",
    "\n",
    "with open(pickle_fname, 'rb') as infile:\n",
    "    prediction_data = pickle.load(infile)\n",
    "\n",
    "data = view_data.get_data('evaluate')\n",
    "\n",
    "batch_size = len(prediction_data['truth']['out_char'])\n",
    "\n",
    "for j in range(10):\n",
    "    predicted_char = int_to_char[np.argmax(prediction_data['result']['out_char'][j])]\n",
    "    correct_char = int_to_char[np.argmax(data['out_char'][j])]\n",
    "    print(\n",
    "        '\"%s\" --> \"%s\"' % (\n",
    "            ''.join([\n",
    "                int_to_char[np.argmax(_)]\n",
    "                for _ in data['in_seq'][j]\n",
    "            ]),\n",
    "            predicted_char\n",
    "        )\n",
    "    )\n",
    "    if predicted_char == correct_char:\n",
    "        print((' ' * (seq_len + 5)) + 'CORRECT')\n",
    "    else:\n",
    "        print((' ' * (seq_len + 5)) + 'INCORRECT (%s)' % correct_char)\n",
    "\n",
    "accuracy = sum(\n",
    "    [\n",
    "        int(\n",
    "            np.argmax(prediction_data['result']['out_char'][i]) == np.argmax(prediction_data['truth']['out_char'][i])\n",
    "        )\n",
    "        for i in range(batch_size)\n",
    "    ]\n",
    ") / float(len(prediction_data['truth']['out_char']))\n",
    "\n",
    "print('accuracy = %s' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ng your time with me. mr. bing\" --> \"l\"\r\n",
      "                                   CORRECT\r\n",
      "\"g your time with me. mr. bingl\" --> \"e\"\r\n",
      "                                   CORRECT\r\n",
      "\" your time with me. mr. bingle\" --> \"y\"\r\n",
      "                                   CORRECT\r\n",
      "\"your time with me. mr. bingley\" --> \" \"\r\n",
      "                                   CORRECT\r\n",
      "\"our time with me. mr. bingley \" --> \"w\"\r\n",
      "                                   INCORRECT (f)\r\n",
      "\"ur time with me. mr. bingley f\" --> \"o\"\r\n",
      "                                   CORRECT\r\n",
      "\"r time with me. mr. bingley fo\" --> \"r\"\r\n",
      "                                   INCORRECT (l)\r\n",
      "\" time with me. mr. bingley fol\" --> \" \"\r\n",
      "                                   INCORRECT (l)\r\n",
      "\"time with me. mr. bingley foll\" --> \" \"\r\n",
      "                                   INCORRECT (o)\r\n",
      "\"ime with me. mr. bingley follo\" --> \"w\"\r\n",
      "                                   CORRECT\r\n",
      "accuracy = 0.470517448856799\r\n"
     ]
    }
   ],
   "source": [
    "!python view_outputs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Test \n",
    "- it only provides us with test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-04 13:02:48,894 kur.kurfile:699]\u001b[0m Parsing source: char_rnn_demo.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:48,908 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:49,241 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:49,241 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:49,241 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:50,614 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:50,615 kur.model.model:260]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:50,615 kur.model.model:265]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:50,616 kur.model.model:280]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:52,010 kur.model.model:284]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:52,011 kur.model.model:285]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:56,837 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Testing, loss=2.701: 100%|██████████████| 831/831 [00:01<00:00, 691.09samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 13:02:58,171 kur.model.executor:197]\u001b[0m Test loss: 2.701\u001b[0m\n",
      "CPU times: user 175 ms, sys: 58.3 ms, total: 234 ms\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kur -v test char_rnn_demo.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__pycache__\u001b[m\u001b[m/                 make_data.py\r\n",
      "\u001b[34mbooks\u001b[m\u001b[m/                       steps.sh\r\n",
      "char_rnn_demo.yaml           \u001b[34mt1\u001b[m\u001b[m/\r\n",
      "char_rnn_demo_defaults.yaml  view_data.py\r\n",
      "char_rnn_kur.ipynb           view_logs.py\r\n",
      "char_rrn_demo_fluid.yaml     view_outputs.py\r\n",
      "cleaned.txt                  vocab.py\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Adding dropout to reduce overfitting and divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing char_rnn_demo_dp_defaults.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile char_rnn_demo_dp_defaults.yaml\n",
    "\n",
    "---\n",
    "\n",
    "settings:\n",
    "\n",
    "  vocab:\n",
    "    size: 30\n",
    "\n",
    "  rnn:\n",
    "    size: 128\n",
    "    depth: 3\n",
    "\n",
    "model:\n",
    "  - input: in_seq\n",
    "\n",
    "  - for:\n",
    "      range: \"{{ rnn.depth - 1 }}\"\n",
    "      iterate:\n",
    "        - recurrent:\n",
    "            size: \"{{ rnn.size }}\"\n",
    "            type: gru\n",
    "            sequence: yes\n",
    "            bidirectional: no\n",
    "        - batch_normalization\n",
    "        - dropout: \"{{drop_neurons}}\"              # only add dropout to first 2 gru layers\n",
    "\n",
    "  - recurrent:\n",
    "      size: \"{{ rnn.size }}\"\n",
    "      type: gru\n",
    "      sequence: no\n",
    "      bidirectional: no\n",
    "  - dropout: \"{{drop_neurons}}\"                    # add dropout\n",
    "\n",
    "  - dense: \"{{ vocab.size }}\"\n",
    "\n",
    "  - activation: softmax\n",
    "\n",
    "  - output: out_char                               # make a name of output layer\n",
    "           \n",
    "\n",
    "loss:\n",
    "  - target: out_char\n",
    "    name: categorical_crossentropy\n",
    "\n",
    "train:\n",
    "  data:\n",
    "    - jsonl: data/train.jsonl\n",
    "  epochs: \"{{ num_epochs|default(5) }}\"     \n",
    "  weights:\n",
    "    initial: t2_dp/best.w.kur\n",
    "    best: t2_dp/best.w.kur\n",
    "    last: t2_dp/last.w.kur\n",
    "  log: t2_dp/log\n",
    "  hooks:                                   \n",
    "    - plot: t2_dp/loss.png\n",
    "\n",
    "validate:\n",
    "  data:\n",
    "    - jsonl: data/validate.jsonl\n",
    "  weights: t2_dp/best.w.kur\n",
    "\n",
    "\n",
    "test:\n",
    "  data:\n",
    "    - jsonl: data/test.jsonl\n",
    "  weights: t2_dp/best.w.kur\n",
    "\n",
    "\n",
    "evaluate:\n",
    "  data:\n",
    "    - jsonl: data/evaluate.jsonl\n",
    "  weights: t2_dp/best.w.kur\n",
    "\n",
    "  destination: t2_dp/output.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting char_rrn_demo_dp_fluid.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile char_rrn_demo_dp_fluid.yaml\n",
    "\n",
    "---\n",
    "settings: \n",
    "  num_epochs: 1                    # leave it empty means inf number of epochs\n",
    "                                 # so to use default value, just comment this line out\n",
    "  drop_neurons: 0.25\n",
    "\n",
    "\n",
    "include: char_rnn_demo_dp_defaults.yaml\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-04 18:41:51,516 kur.kurfile:699]\u001b[0m Parsing source: char_rrn_demo_dp_fluid.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:51,520 kur.kurfile:699]\u001b[0m Parsing source: char_rnn_demo_dp_defaults.yaml, included by char_rrn_demo_dp_fluid.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:51,531 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,531 kur.kurfile:784]\u001b[0m Parsing Kurfile section: settings\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,532 kur.kurfile:784]\u001b[0m Parsing Kurfile section: train\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,536 kur.kurfile:784]\u001b[0m Parsing Kurfile section: validate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,537 kur.kurfile:784]\u001b[0m Parsing Kurfile section: test\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,539 kur.kurfile:784]\u001b[0m Parsing Kurfile section: evaluate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,541 kur.containers.layers.placeholder:63]\u001b[0m Using short-hand name for placeholder: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,542 kur.containers.layers.placeholder:97]\u001b[0m Placeholder \"in_seq\" has a deferred shape.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,552 kur.containers.layers.output:50]\u001b[0m Using short-hand name for output: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,552 kur.kurfile:784]\u001b[0m Parsing Kurfile section: loss\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:51,554 kur.loggers.binary_logger:71]\u001b[0m Loading log data: t2_dp/log\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,554 kur.loggers.binary_logger:158]\u001b[0m Reading logger summary.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,556 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: training_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,557 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: training_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,558 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: training_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,559 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,560 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:51,560 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:54,984 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:55,240 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:55,241 kur.backend.backend:187]\u001b[0m Using backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:55,241 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:55,242 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:55,242 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:55,242 kur.backend.keras_backend:124]\u001b[0m Using the system-default Keras backend.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:55,242 kur.backend.keras_backend:189]\u001b[0m Overriding environmental variables: {'TF_CPP_MIN_LOG_LEVEL': '1', 'KERAS_BACKEND': None, 'THEANO_FLAGS': None}\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:56,246 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:56,246 kur.model.model:260]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:56,247 kur.model.model:265]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:272]\u001b[0m Assembled Node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:274]\u001b[0m   Uses: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:276]\u001b[0m   Used by: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:277]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:272]\u001b[0m Assembled Node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:274]\u001b[0m   Uses: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:276]\u001b[0m   Used by: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:277]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:272]\u001b[0m Assembled Node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:274]\u001b[0m   Uses: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:276]\u001b[0m   Used by: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:277]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:272]\u001b[0m Assembled Node: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,247 kur.model.model:274]\u001b[0m   Uses: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:276]\u001b[0m   Used by: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:277]\u001b[0m   Aliases: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:272]\u001b[0m Assembled Node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:274]\u001b[0m   Uses: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:276]\u001b[0m   Used by: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:277]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:272]\u001b[0m Assembled Node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:274]\u001b[0m   Uses: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:276]\u001b[0m   Used by: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:277]\u001b[0m   Aliases: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:272]\u001b[0m Assembled Node: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:274]\u001b[0m   Uses: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:276]\u001b[0m   Used by: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:277]\u001b[0m   Aliases: ..dropout.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:272]\u001b[0m Assembled Node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:274]\u001b[0m   Uses: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:276]\u001b[0m   Used by: ..dropout.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:277]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:272]\u001b[0m Assembled Node: ..dropout.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:274]\u001b[0m   Uses: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,248 kur.model.model:276]\u001b[0m   Used by: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:277]\u001b[0m   Aliases: ..dropout.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:272]\u001b[0m Assembled Node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:274]\u001b[0m   Uses: ..dropout.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:276]\u001b[0m   Used by: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:277]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:272]\u001b[0m Assembled Node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:274]\u001b[0m   Uses: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:276]\u001b[0m   Used by: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:277]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:272]\u001b[0m Assembled Node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:274]\u001b[0m   Uses: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:276]\u001b[0m   Used by: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:277]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:56,249 kur.model.model:280]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:311]\u001b[0m Building node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:312]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.containers.layers.placeholder:117]\u001b[0m Creating placeholder for \"in_seq\" with data type \"float32\".\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:125]\u001b[0m Trying to infer shape for input \"in_seq\"\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.model.model:143]\u001b[0m Inferred shape for input \"in_seq\": (30, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,249 kur.containers.layers.placeholder:127]\u001b[0m Inferred shape: (30, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,254 kur.model.model:382]\u001b[0m   Value: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,254 kur.model.model:311]\u001b[0m Building node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,254 kur.model.model:312]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,254 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:56,254 kur.model.model:315]\u001b[0m   - in_seq: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,187 kur.model.model:382]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,187 kur.model.model:311]\u001b[0m Building node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,187 kur.model.model:312]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,187 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,187 kur.model.model:315]\u001b[0m   - ..recurrent.0: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,206 kur.model.model:382]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,206 kur.model.model:311]\u001b[0m Building node: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,206 kur.model.model:312]\u001b[0m   Aliases: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,206 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:57,206 kur.model.model:315]\u001b[0m   - ..batch_normalization.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,018 kur.model.model:382]\u001b[0m   Value: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,018 kur.model.model:311]\u001b[0m Building node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,018 kur.model.model:312]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,018 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,018 kur.model.model:315]\u001b[0m   - ..dropout.0: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,062 kur.model.model:382]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,062 kur.model.model:311]\u001b[0m Building node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,062 kur.model.model:312]\u001b[0m   Aliases: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,062 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,062 kur.model.model:315]\u001b[0m   - ..recurrent.1: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,073 kur.model.model:382]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,074 kur.model.model:311]\u001b[0m Building node: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,074 kur.model.model:312]\u001b[0m   Aliases: ..dropout.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,074 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,074 kur.model.model:315]\u001b[0m   - ..batch_normalization.1: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,142 kur.model.model:382]\u001b[0m   Value: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,142 kur.model.model:311]\u001b[0m Building node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,142 kur.model.model:312]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,142 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,142 kur.model.model:315]\u001b[0m   - ..dropout.1: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,290 kur.model.model:382]\u001b[0m   Value: Subtensor{int64}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,290 kur.model.model:311]\u001b[0m Building node: ..dropout.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,291 kur.model.model:312]\u001b[0m   Aliases: ..dropout.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,291 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,291 kur.model.model:315]\u001b[0m   - ..recurrent.2: Subtensor{int64}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,349 kur.model.model:382]\u001b[0m   Value: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,349 kur.model.model:311]\u001b[0m Building node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,349 kur.model.model:312]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,349 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,349 kur.model.model:315]\u001b[0m   - ..dropout.2: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,351 kur.model.model:382]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,351 kur.model.model:311]\u001b[0m Building node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,351 kur.model.model:312]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,351 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,351 kur.model.model:315]\u001b[0m   - ..dense.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,351 kur.model.model:382]\u001b[0m   Value: Softmax.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,352 kur.model.model:311]\u001b[0m Building node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,352 kur.model.model:312]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,352 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,352 kur.model.model:315]\u001b[0m   - ..activation.0: Softmax.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,352 kur.model.model:382]\u001b[0m   Value: Softmax.0\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:58,352 kur.model.model:284]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:58,352 kur.model.model:285]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,352 kur.model.model:229]\u001b[0m Loading model weights from: t2_dp/best.w.kur\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:58,387 kur.model.executor:313]\u001b[0m Best historical training loss: 1.305\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:58,388 kur.model.executor:320]\u001b[0m Best historical validation loss: 1.602\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:41:58,388 kur.model.executor:331]\u001b[0m Restarting from epoch 22.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,388 kur.model.executor:353]\u001b[0m Epoch handling mode: additional\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,388 kur.model.executor:101]\u001b[0m Recompiling the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:58,388 kur.backend.keras_backend:527]\u001b[0m Instantiating a Keras model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m Layer (type)                     Output Shape          Param #     Connected to                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m in_seq (InputLayer)              (None, 30, 30)        0                                            \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m ..recurrent.0 (GRU)              (None, 30, 128)       61056       in_seq[0][0]                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.0 (BatchNo (None, 30, 128)       512         ..recurrent.0[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,441 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,442 kur.backend.keras_backend:538]\u001b[0m ..dropout.0 (Dropout)            (None, 30, 128)       0           ..batch_normalization.0[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,442 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,442 kur.backend.keras_backend:538]\u001b[0m ..recurrent.1 (GRU)              (None, 30, 128)       98688       ..dropout.0[0][0]                \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,442 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,442 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.1 (BatchNo (None, 30, 128)       512         ..recurrent.1[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,442 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,442 kur.backend.keras_backend:538]\u001b[0m ..dropout.1 (Dropout)            (None, 30, 128)       0           ..batch_normalization.1[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,442 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ..recurrent.2 (GRU)              (None, 128)           98688       ..dropout.1[0][0]                \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ..dropout.2 (Dropout)            (None, 128)           0           ..recurrent.2[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ..dense.0 (Dense)                (None, 30)            3870        ..dropout.2[0][0]                \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ..activation.0 (Activation)      (None, 30)            0           ..dense.0[0][0]                  \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m Total params: 263,326\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m Trainable params: 262,814\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m Non-trainable params: 512\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,443 kur.backend.keras_backend:538]\u001b[0m \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,444 kur.backend.keras_backend:576]\u001b[0m Assembling a training function from the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:41:59,454 kur.backend.keras_backend:509]\u001b[0m Adding additional inputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:22,926 kur.backend.keras_backend:599]\u001b[0m Additional inputs for log functions: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:22,926 kur.backend.keras_backend:616]\u001b[0m Expected input shapes: in_seq=(None, 30, 30), out_char=(None, None)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:22,926 kur.backend.keras_backend:634]\u001b[0m Compiled model: {'names': {'input': ['in_seq', 'out_char'], 'output': ['..activation.0', 'out_char']}, 'func': <keras.backend.theano_backend.Function object at 0x11a9d7cf8>, 'shapes': {'input': [(None, 30, 30), (None, None)]}}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:22,926 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:22,926 kur.providers.batch_provider:102]\u001b[0m Maximum number of batches set to: 1\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:42:22,944 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:22,944 kur.providers.batch_provider:139]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:22,944 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,070 kur.providers.provider:144]\u001b[0m Data source \"in_seq\": entries=13300, shape=(30, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,070 kur.providers.provider:144]\u001b[0m Data source \"out_char\": entries=13300, shape=(30,)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,366 kur.model.hooks.plot_hook:73]\u001b[0m Plotting hook received training message.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,366 kur.model.hooks.plot_hook:80]\u001b[0m Plotting hook does not handle this status.\u001b[0m\n",
      "\n",
      "Epoch 22/22, loss=N/A:   0%|                     | 0/13300 [00:00<?, ?samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:23,373 kur.providers.shuffle_provider:184]\u001b[0m Shuffling...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,510 kur.providers.batch_provider:139]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,510 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,510 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,510 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,516 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,649 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,650 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,651 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,652 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,652 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,653 kur.loggers.binary_logger:144]\u001b[0m Writing logger summary.\u001b[0m\n",
      "Epoch 22/22, loss=1.155:   0%|         | 32/13300 [00:00<01:56, 113.59samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:23,654 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,654 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,656 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,765 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.349:   0%|         | 64/13300 [00:00<01:35, 138.71samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:23,766 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,766 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,767 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,874 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.318:   1%|         | 96/13300 [00:00<01:20, 164.89samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:23,874 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,875 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,876 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,983 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.292:   1%|        | 128/13300 [00:00<01:09, 189.71samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:23,984 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,984 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:23,986 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,112 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.338:   1%|        | 160/13300 [00:00<01:04, 204.13samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:24,113 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,113 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,115 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,244 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.290:   1%|        | 192/13300 [00:00<01:01, 214.36samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:24,245 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,245 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,247 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,368 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.229:   2%|▏       | 224/13300 [00:00<00:57, 226.15samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:24,368 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,368 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,370 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,466 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,466 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,466 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,468 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,589 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.246:   2%|▏       | 288/13300 [00:01<00:53, 242.02samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:24,589 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,589 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,591 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,705 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.252:   2%|▏       | 320/13300 [00:01<00:51, 251.18samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:24,705 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,705 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,707 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,827 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.252:   3%|▏       | 352/13300 [00:01<00:50, 254.32samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:24,827 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,828 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,829 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,943 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.256:   3%|▏       | 384/13300 [00:01<00:49, 260.54samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:24,943 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,943 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:24,945 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,073 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.225:   3%|▎       | 416/13300 [00:01<00:50, 256.17samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:25,073 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,073 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,074 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,174 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.234:   3%|▎       | 448/13300 [00:01<00:47, 271.59samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:25,174 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,175 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,176 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,304 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.244:   4%|▎       | 480/13300 [00:01<00:48, 263.01samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:25,305 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,305 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,307 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,430 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.241:   4%|▎       | 512/13300 [00:02<00:49, 260.80samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:25,430 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,430 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,432 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,553 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.216:   4%|▎       | 544/13300 [00:02<00:48, 260.63samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:25,553 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,553 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,554 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,674 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.226:   4%|▎       | 576/13300 [00:02<00:48, 261.29samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:25,675 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,675 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,676 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,776 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.201:   5%|▎       | 608/13300 [00:02<00:46, 275.41samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:25,776 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,777 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,778 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,893 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.223:   5%|▍       | 640/13300 [00:02<00:46, 274.65samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:25,894 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,894 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:25,895 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,006 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.222:   5%|▍       | 672/13300 [00:02<00:45, 277.42samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,006 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,006 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,008 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,123 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.239:   5%|▍       | 704/13300 [00:02<00:45, 276.36samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,123 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,123 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,125 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,240 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.241:   6%|▍       | 736/13300 [00:02<00:45, 275.05samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,241 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,241 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,242 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,358 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.245:   6%|▍       | 768/13300 [00:02<00:45, 273.92samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,359 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,359 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,360 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,482 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.244:   6%|▍       | 800/13300 [00:03<00:46, 269.35samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,482 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,482 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,483 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,587 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.244:   6%|▌       | 832/13300 [00:03<00:44, 279.00samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,587 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,588 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,589 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,703 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:   6%|▌       | 864/13300 [00:03<00:44, 277.89samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,703 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,703 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,705 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,826 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:   7%|▌       | 896/13300 [00:03<00:45, 272.23samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,827 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,827 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,828 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,939 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.270:   7%|▌       | 928/13300 [00:03<00:44, 275.57samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:26,939 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,939 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:26,941 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,061 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.284:   7%|▌       | 960/13300 [00:03<00:45, 271.57samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:27,061 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,061 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,062 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,172 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.289:   7%|▌       | 992/13300 [00:03<00:44, 275.93samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:27,173 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,173 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,175 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,299 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.284:   8%|▌      | 1024/13300 [00:03<00:45, 268.77samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:27,299 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,299 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,301 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,416 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.287:   8%|▌      | 1056/13300 [00:04<00:45, 270.03samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:27,416 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,416 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,418 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,549 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.302:   8%|▌      | 1088/13300 [00:04<00:46, 260.37samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:27,549 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,550 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,551 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,671 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.297:   8%|▌      | 1120/13300 [00:04<00:46, 260.76samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:27,672 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,673 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,673 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,803 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.295:   9%|▌      | 1152/13300 [00:04<00:47, 255.35samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:27,803 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,803 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,805 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,922 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.299:   9%|▌      | 1184/13300 [00:04<00:46, 258.93samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:27,923 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,923 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:27,924 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,045 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.297:   9%|▋      | 1216/13300 [00:04<00:46, 259.10samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,046 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,046 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,047 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,166 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.297:   9%|▋      | 1248/13300 [00:04<00:46, 260.73samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,167 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,167 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,169 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,281 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.295:  10%|▋      | 1280/13300 [00:04<00:45, 266.08samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,281 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,282 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,283 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,399 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.296:  10%|▋      | 1312/13300 [00:05<00:44, 267.27samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,400 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,400 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,402 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,520 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.293:  10%|▋      | 1344/13300 [00:05<00:44, 266.56samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,521 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,521 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,522 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,641 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.288:  10%|▋      | 1376/13300 [00:05<00:44, 266.04samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,641 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,642 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,643 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,762 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.278:  11%|▋      | 1408/13300 [00:05<00:44, 265.37samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,763 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,763 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,765 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,868 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.284:  11%|▊      | 1440/13300 [00:05<00:42, 275.95samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,868 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,868 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,870 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,989 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.282:  11%|▊      | 1472/13300 [00:05<00:43, 271.75samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:28,990 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,990 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:28,992 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,113 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.277:  11%|▊      | 1504/13300 [00:05<00:44, 267.75samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:29,113 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,114 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,115 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,230 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.281:  12%|▊      | 1536/13300 [00:05<00:43, 269.32samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:29,231 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,231 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,233 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,354 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.280:  12%|▊      | 1568/13300 [00:05<00:44, 266.19samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:29,354 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,354 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,356 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,473 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.281:  12%|▊      | 1600/13300 [00:06<00:43, 266.68samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:29,474 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,474 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,475 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,579 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.287:  12%|▊      | 1632/13300 [00:06<00:42, 276.18samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:29,580 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,580 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,582 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,704 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.290:  13%|▉      | 1664/13300 [00:06<00:43, 270.17samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:29,704 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,705 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,706 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,816 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.284:  13%|▉      | 1696/13300 [00:06<00:42, 274.90samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:29,816 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,816 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,818 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,943 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.278:  13%|▉      | 1728/13300 [00:06<00:43, 267.58samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:29,943 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,943 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:29,945 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,064 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.281:  13%|▉      | 1760/13300 [00:06<00:43, 266.36samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:30,064 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,065 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,066 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,185 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.286:  13%|▉      | 1792/13300 [00:06<00:43, 265.57samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:30,186 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,186 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,188 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,311 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.290:  14%|▉      | 1824/13300 [00:06<00:43, 261.92samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:30,312 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,312 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,314 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,436 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.299:  14%|▉      | 1856/13300 [00:07<00:43, 260.44samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:30,437 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,437 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,439 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,570 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.290:  14%|▉      | 1888/13300 [00:07<00:45, 253.37samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:30,571 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,571 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,572 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,708 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.286:  14%|█      | 1920/13300 [00:07<00:46, 246.74samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:30,708 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,709 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,711 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,855 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.285:  15%|█      | 1952/13300 [00:07<00:47, 237.30samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:30,855 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,855 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,857 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,994 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.281:  15%|█      | 1984/13300 [00:07<00:48, 234.77samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:30,995 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,996 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:30,997 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,120 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.276:  15%|█      | 2016/13300 [00:07<00:46, 240.40samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:31,121 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,121 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,122 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,232 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.278:  15%|█      | 2048/13300 [00:07<00:44, 252.46samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:31,232 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,233 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,234 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,362 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.269:  16%|█      | 2080/13300 [00:07<00:44, 250.32samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:31,363 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,363 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,364 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,502 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.269:  16%|█      | 2112/13300 [00:08<00:45, 243.85samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:31,502 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,502 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,504 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,632 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.268:  16%|█▏     | 2144/13300 [00:08<00:45, 244.00samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:31,633 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,633 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,634 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,768 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.280:  16%|█▏     | 2176/13300 [00:08<00:46, 241.18samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:31,770 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,770 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,773 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,903 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.274:  17%|█▏     | 2208/13300 [00:08<00:46, 240.44samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:31,903 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,903 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:31,905 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,033 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.272:  17%|█▏     | 2240/13300 [00:08<00:45, 241.93samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:32,034 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,036 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,036 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,179 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.272:  17%|█▏     | 2272/13300 [00:08<00:46, 234.91samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:32,179 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,179 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,182 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,314 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.272:  17%|█▏     | 2304/13300 [00:08<00:46, 235.34samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:32,314 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,315 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,317 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,438 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.268:  18%|█▏     | 2336/13300 [00:09<00:45, 241.84samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:32,438 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,438 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,439 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,564 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.266:  18%|█▏     | 2368/13300 [00:09<00:44, 245.51samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:32,564 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,564 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,566 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,683 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.274:  18%|█▎     | 2400/13300 [00:09<00:43, 251.71samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:32,684 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,684 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,686 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,805 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.280:  18%|█▎     | 2432/13300 [00:09<00:42, 255.04samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:32,805 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,806 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,807 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,936 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.281:  19%|█▎     | 2464/13300 [00:09<00:43, 251.47samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:32,936 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,937 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:32,938 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,056 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.282:  19%|█▎     | 2496/13300 [00:09<00:42, 256.14samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:33,056 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,056 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,058 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,178 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.280:  19%|█▎     | 2528/13300 [00:09<00:41, 257.55samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:33,179 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,179 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,181 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,298 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.283:  19%|█▎     | 2560/13300 [00:09<00:41, 260.48samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:33,298 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,300 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,300 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,423 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.285:  19%|█▎     | 2592/13300 [00:10<00:41, 258.98samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:33,423 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,424 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,425 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,539 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.286:  20%|█▍     | 2624/13300 [00:10<00:40, 264.11samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:33,539 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,539 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,541 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,663 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.282:  20%|█▍     | 2656/13300 [00:10<00:40, 262.35samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:33,663 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,663 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,665 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,789 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.283:  20%|█▍     | 2688/13300 [00:10<00:40, 259.42samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:33,790 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,790 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,791 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,924 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.282:  20%|█▍     | 2720/13300 [00:10<00:41, 252.19samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:33,925 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,925 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:33,926 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,052 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.280:  21%|█▍     | 2752/13300 [00:10<00:41, 251.43samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:34,053 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,053 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,055 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,179 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.275:  21%|█▍     | 2784/13300 [00:10<00:41, 252.12samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:34,179 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,179 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,181 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,313 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.276:  21%|█▍     | 2816/13300 [00:10<00:42, 247.67samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:34,314 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,314 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,315 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,449 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.275:  21%|█▍     | 2848/13300 [00:11<00:42, 243.84samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:34,449 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,450 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,451 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,578 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.274:  22%|█▌     | 2880/13300 [00:11<00:42, 245.37samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:34,578 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,578 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,580 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,700 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.275:  22%|█▌     | 2912/13300 [00:11<00:41, 249.80samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:34,701 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,701 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,702 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,853 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.274:  22%|█▌     | 2944/13300 [00:11<00:43, 236.38samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:34,853 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,853 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,855 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,985 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.276:  22%|█▌     | 2976/13300 [00:11<00:43, 237.74samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:34,986 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,986 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:34,988 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,116 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.277:  23%|█▌     | 3008/13300 [00:11<00:42, 239.64samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:35,117 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,117 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,119 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,244 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.272:  23%|█▌     | 3040/13300 [00:11<00:42, 243.06samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:35,244 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,245 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,246 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,373 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.272:  23%|█▌     | 3072/13300 [00:12<00:41, 244.25samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:35,374 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,374 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,375 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,527 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.271:  23%|█▋     | 3104/13300 [00:12<00:43, 232.02samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:35,528 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,528 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,530 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,658 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.268:  24%|█▋     | 3136/13300 [00:12<00:43, 235.90samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:35,658 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,658 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,660 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,798 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.269:  24%|█▋     | 3168/13300 [00:12<00:43, 233.71samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:35,798 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,798 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,800 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,927 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.268:  24%|█▋     | 3200/13300 [00:12<00:42, 237.80samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:35,927 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,927 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:35,929 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,047 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.269:  24%|█▋     | 3232/13300 [00:12<00:40, 245.59samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:36,047 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,048 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,049 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,174 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.270:  25%|█▋     | 3264/13300 [00:12<00:40, 247.44samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:36,174 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,175 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,176 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,296 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.269:  25%|█▋     | 3296/13300 [00:12<00:39, 251.63samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:36,297 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,297 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,298 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,423 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.268:  25%|█▊     | 3328/13300 [00:13<00:39, 251.85samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:36,423 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,424 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,425 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,547 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.267:  25%|█▊     | 3360/13300 [00:13<00:39, 253.75samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:36,547 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,547 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,549 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,672 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  26%|█▊     | 3392/13300 [00:13<00:38, 254.48samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:36,672 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,673 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,675 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,799 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.264:  26%|█▊     | 3424/13300 [00:13<00:38, 253.84samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:36,799 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,799 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,801 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,931 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  26%|█▊     | 3456/13300 [00:13<00:39, 249.88samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:36,932 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,932 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:36,933 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,055 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  26%|█▊     | 3488/13300 [00:13<00:38, 252.55samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:37,055 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,055 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,056 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,185 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.266:  26%|█▊     | 3520/13300 [00:13<00:39, 250.49samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:37,186 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,186 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,187 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,315 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.266:  27%|█▊     | 3552/13300 [00:13<00:39, 249.01samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:37,316 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,316 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,317 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,445 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.267:  27%|█▉     | 3584/13300 [00:14<00:39, 248.26samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:37,446 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,446 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,447 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,566 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  27%|█▉     | 3616/13300 [00:14<00:38, 253.01samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:37,567 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,567 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,569 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,692 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  27%|█▉     | 3648/13300 [00:14<00:38, 253.23samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:37,693 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,693 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,694 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,811 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  28%|█▉     | 3680/13300 [00:14<00:37, 257.61samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:37,812 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,812 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,813 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,932 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  28%|█▉     | 3712/13300 [00:14<00:36, 259.48samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:37,933 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,933 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:37,935 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,082 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  28%|█▉     | 3744/13300 [00:14<00:39, 243.86samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:38,083 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,083 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,084 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,203 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  28%|█▉     | 3776/13300 [00:14<00:38, 249.84samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:38,203 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,203 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,205 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,326 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  29%|██     | 3808/13300 [00:14<00:37, 252.54samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:38,327 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,327 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,329 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,453 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  29%|██     | 3840/13300 [00:15<00:37, 252.31samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:38,454 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,454 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,456 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,574 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  29%|██     | 3872/13300 [00:15<00:36, 256.09samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:38,574 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,575 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,576 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,697 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  29%|██     | 3904/13300 [00:15<00:36, 257.25samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:38,698 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,698 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,700 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,826 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.264:  30%|██     | 3936/13300 [00:15<00:36, 254.62samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:38,826 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,826 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,828 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,941 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  30%|██     | 3968/13300 [00:15<00:35, 261.15samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:38,942 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,942 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:38,943 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,065 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  30%|██     | 4000/13300 [00:15<00:35, 260.40samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:39,065 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,065 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,067 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,182 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.255:  30%|██     | 4032/13300 [00:15<00:35, 263.79samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:39,183 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,183 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,184 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,306 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.257:  31%|██▏    | 4064/13300 [00:15<00:35, 262.38samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:39,306 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,306 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,308 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,432 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  31%|██▏    | 4096/13300 [00:16<00:35, 260.03samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:39,432 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,432 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,433 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,558 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.257:  31%|██▏    | 4128/13300 [00:16<00:35, 257.86samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:39,558 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,559 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,560 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,679 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  31%|██▏    | 4160/13300 [00:16<00:35, 260.10samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:39,679 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,679 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,681 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,805 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  32%|██▏    | 4192/13300 [00:16<00:35, 257.87samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:39,806 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,806 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,808 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,926 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.256:  32%|██▏    | 4224/13300 [00:16<00:34, 259.98samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:39,926 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,927 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:39,927 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,046 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  32%|██▏    | 4256/13300 [00:16<00:34, 262.20samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:40,046 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,046 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,049 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,174 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.256:  32%|██▎    | 4288/13300 [00:16<00:34, 258.26samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:40,174 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,174 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,176 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,290 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.256:  32%|██▎    | 4320/13300 [00:16<00:34, 263.21samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:40,290 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,290 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,292 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,417 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.257:  33%|██▎    | 4352/13300 [00:17<00:34, 259.85samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:40,417 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,417 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,419 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,533 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.257:  33%|██▎    | 4384/13300 [00:17<00:33, 263.98samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:40,534 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,534 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,535 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,653 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.256:  33%|██▎    | 4416/13300 [00:17<00:33, 265.26samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:40,653 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,653 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,655 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,777 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.253:  33%|██▎    | 4448/13300 [00:17<00:33, 263.12samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:40,777 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,777 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,779 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,893 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.253:  34%|██▎    | 4480/13300 [00:17<00:33, 266.76samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:40,893 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,893 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:40,895 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,006 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.254:  34%|██▎    | 4512/13300 [00:17<00:32, 271.32samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,006 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,007 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,008 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,127 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.254:  34%|██▍    | 4544/13300 [00:17<00:32, 269.18samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,128 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,128 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,129 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,244 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.253:  34%|██▍    | 4576/13300 [00:17<00:32, 270.45samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,244 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,245 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,246 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,363 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.254:  35%|██▍    | 4608/13300 [00:17<00:32, 269.79samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,364 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,364 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,365 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,491 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.254:  35%|██▍    | 4640/13300 [00:18<00:32, 263.91samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,491 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,491 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,493 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,611 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.251:  35%|██▍    | 4672/13300 [00:18<00:32, 264.40samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,612 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,612 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,613 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,722 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.251:  35%|██▍    | 4704/13300 [00:18<00:31, 270.99samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,723 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,723 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,725 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,870 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.254:  36%|██▍    | 4736/13300 [00:18<00:33, 252.31samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,870 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,870 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,872 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,982 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.257:  36%|██▌    | 4768/13300 [00:18<00:32, 261.29samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:41,982 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,983 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:41,984 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,120 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  36%|██▌    | 4800/13300 [00:18<00:33, 251.94samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:42,120 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,120 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,122 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,255 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  36%|██▌    | 4832/13300 [00:18<00:34, 247.12samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:42,255 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,256 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,257 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,367 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  37%|██▌    | 4864/13300 [00:18<00:32, 257.62samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:42,367 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,368 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,369 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,485 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  37%|██▌    | 4896/13300 [00:19<00:32, 261.47samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:42,485 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,485 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,487 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,604 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  37%|██▌    | 4928/13300 [00:19<00:31, 263.65samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:42,604 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,605 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,606 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,735 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  37%|██▌    | 4960/13300 [00:19<00:32, 257.30samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:42,736 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,736 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,738 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,851 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.256:  38%|██▋    | 4992/13300 [00:19<00:31, 262.75samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:42,852 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,852 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,853 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,968 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  38%|██▋    | 5024/13300 [00:19<00:31, 266.15samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:42,968 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,968 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:42,970 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,098 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  38%|██▋    | 5056/13300 [00:19<00:31, 259.64samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:43,098 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,099 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,100 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,217 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  38%|██▋    | 5088/13300 [00:19<00:31, 262.16samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:43,218 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,218 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,219 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,338 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  38%|██▋    | 5120/13300 [00:19<00:31, 262.83samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:43,339 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,339 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,341 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,458 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.256:  39%|██▋    | 5152/13300 [00:20<00:30, 264.42samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:43,458 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,458 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,460 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,582 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.255:  39%|██▋    | 5184/13300 [00:20<00:30, 262.21samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:43,583 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,583 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,584 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,700 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.256:  39%|██▋    | 5216/13300 [00:20<00:30, 265.12samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:43,700 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,700 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,702 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,816 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.257:  39%|██▊    | 5248/13300 [00:20<00:30, 267.75samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:43,817 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,817 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,818 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,937 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  40%|██▊    | 5280/13300 [00:20<00:30, 266.94samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:43,938 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,938 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:43,940 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,056 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  40%|██▊    | 5312/13300 [00:20<00:29, 267.86samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:44,056 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,056 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,058 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,178 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  40%|██▊    | 5344/13300 [00:20<00:29, 266.16samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:44,178 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,178 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,180 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,305 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  40%|██▊    | 5376/13300 [00:20<00:30, 261.53samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:44,305 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,306 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,307 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,426 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.257:  41%|██▊    | 5408/13300 [00:21<00:30, 262.45samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:44,426 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,426 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,428 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,547 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  41%|██▊    | 5440/13300 [00:21<00:29, 262.98samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:44,547 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,548 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,549 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,670 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  41%|██▉    | 5472/13300 [00:21<00:29, 262.09samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:44,670 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,671 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,672 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,791 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  41%|██▉    | 5504/13300 [00:21<00:29, 263.11samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:44,791 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,791 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,793 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,922 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  42%|██▉    | 5536/13300 [00:21<00:30, 256.97samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:44,922 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,923 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:44,924 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,039 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  42%|██▉    | 5568/13300 [00:21<00:29, 261.49samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:45,040 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,040 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,041 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,158 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  42%|██▉    | 5600/13300 [00:21<00:29, 263.60samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:45,159 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,159 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,160 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,287 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  42%|██▉    | 5632/13300 [00:21<00:29, 258.73samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:45,288 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,288 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,290 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,401 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  43%|██▉    | 5664/13300 [00:22<00:28, 264.86samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:45,402 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,402 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,403 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,522 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  43%|██▉    | 5696/13300 [00:22<00:28, 265.31samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:45,522 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,522 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,524 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,644 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  43%|███    | 5728/13300 [00:22<00:28, 264.47samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:45,644 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,644 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,645 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,773 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  43%|███    | 5760/13300 [00:22<00:29, 259.14samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:45,773 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,773 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,775 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,895 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  44%|███    | 5792/13300 [00:22<00:28, 259.87samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:45,896 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,896 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:45,897 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,014 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.264:  44%|███    | 5824/13300 [00:22<00:28, 262.82samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,014 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,014 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,016 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,136 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  44%|███    | 5856/13300 [00:22<00:28, 262.58samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,136 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,136 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,138 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,252 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  44%|███    | 5888/13300 [00:22<00:27, 266.23samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,253 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,253 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,254 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,373 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  45%|███    | 5920/13300 [00:23<00:27, 265.67samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,374 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,374 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,375 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,499 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  45%|███▏   | 5952/13300 [00:23<00:28, 262.01samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,500 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,500 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,501 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,613 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  45%|███▏   | 5984/13300 [00:23<00:27, 267.64samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,613 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,613 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,615 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,728 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  45%|███▏   | 6016/13300 [00:23<00:26, 270.27samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,729 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,729 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,730 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,846 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  45%|███▏   | 6048/13300 [00:23<00:26, 270.59samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,847 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,847 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,848 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,968 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.264:  46%|███▏   | 6080/13300 [00:23<00:26, 268.35samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:46,968 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,969 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:46,970 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,090 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.266:  46%|███▏   | 6112/13300 [00:23<00:27, 266.17samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:47,091 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,091 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,093 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,210 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  46%|███▏   | 6144/13300 [00:23<00:26, 266.27samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:47,211 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,211 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,213 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,335 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  46%|███▎   | 6176/13300 [00:23<00:27, 263.35samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:47,335 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,336 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,337 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,459 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  47%|███▎   | 6208/13300 [00:24<00:27, 261.86samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:47,459 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,460 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,461 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,575 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  47%|███▎   | 6240/13300 [00:24<00:26, 266.10samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:47,575 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,575 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,577 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,695 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  47%|███▎   | 6272/13300 [00:24<00:26, 266.35samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:47,695 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,695 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,697 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,813 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  47%|███▎   | 6304/13300 [00:24<00:26, 267.26samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:47,814 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,814 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,816 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,946 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.264:  48%|███▎   | 6336/13300 [00:24<00:26, 259.14samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:47,946 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,946 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:47,948 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,067 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.264:  48%|███▎   | 6368/13300 [00:24<00:26, 260.53samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:48,067 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,068 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,069 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,196 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.264:  48%|███▎   | 6400/13300 [00:24<00:26, 256.45samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:48,197 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,197 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,197 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,319 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  48%|███▍   | 6432/13300 [00:24<00:26, 257.73samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:48,319 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,319 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,321 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,443 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.266:  49%|███▍   | 6464/13300 [00:25<00:26, 257.89samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:48,443 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,443 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,445 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,566 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.265:  49%|███▍   | 6496/13300 [00:25<00:26, 258.73samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:48,566 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,566 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,568 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,697 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  49%|███▍   | 6528/13300 [00:25<00:26, 253.88samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:48,698 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,698 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,698 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,816 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  49%|███▍   | 6560/13300 [00:25<00:26, 258.05samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:48,817 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,817 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,818 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,931 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  50%|███▍   | 6592/13300 [00:25<00:25, 263.81samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:48,932 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,932 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:48,934 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,069 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  50%|███▍   | 6624/13300 [00:25<00:26, 253.61samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:49,069 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,069 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,071 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,192 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  50%|███▌   | 6656/13300 [00:25<00:26, 255.24samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:49,193 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,193 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,194 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,314 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  50%|███▌   | 6688/13300 [00:25<00:25, 257.62samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:49,314 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,315 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,316 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,435 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  51%|███▌   | 6720/13300 [00:26<00:25, 259.69samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:49,435 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,435 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,437 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,552 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  51%|███▌   | 6752/13300 [00:26<00:24, 263.30samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:49,553 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,553 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,554 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,676 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  51%|███▌   | 6784/13300 [00:26<00:24, 261.99samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:49,676 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,677 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,678 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,795 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  51%|███▌   | 6816/13300 [00:26<00:24, 263.95samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:49,795 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,796 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,797 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,912 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  51%|███▌   | 6848/13300 [00:26<00:24, 266.73samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:49,913 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,913 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:49,914 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,036 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  52%|███▌   | 6880/13300 [00:26<00:24, 264.21samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:50,036 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,036 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,038 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,151 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  52%|███▋   | 6912/13300 [00:26<00:23, 268.14samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:50,152 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,152 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,153 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,280 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  52%|███▋   | 6944/13300 [00:26<00:24, 262.04samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:50,280 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,280 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,282 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,412 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  52%|███▋   | 6976/13300 [00:27<00:24, 255.57samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:50,413 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,413 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,414 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,554 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  53%|███▋   | 7008/13300 [00:27<00:25, 245.76samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:50,554 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,555 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,556 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,675 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.263:  53%|███▋   | 7040/13300 [00:27<00:24, 251.12samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:50,675 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,676 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,677 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,888 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.264:  53%|███▋   | 7072/13300 [00:27<00:29, 209.06samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:50,888 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,889 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:50,890 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,015 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  53%|███▋   | 7104/13300 [00:27<00:28, 220.15samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:51,016 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,016 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,017 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,146 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.262:  54%|███▊   | 7136/13300 [00:27<00:27, 226.96samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:51,146 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,147 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,148 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,268 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  54%|███▊   | 7168/13300 [00:27<00:25, 236.73samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:51,268 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,268 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,270 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,402 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  54%|███▊   | 7200/13300 [00:28<00:25, 237.09samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:51,403 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,403 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,404 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,531 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  54%|███▊   | 7232/13300 [00:28<00:25, 240.52samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:51,531 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,531 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,533 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,656 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  55%|███▊   | 7264/13300 [00:28<00:24, 244.55samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:51,657 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,657 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,659 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,817 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.261:  55%|███▊   | 7296/13300 [00:28<00:26, 228.94samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:51,818 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,818 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,819 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,963 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  55%|███▊   | 7328/13300 [00:28<00:26, 225.83samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:51,964 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,964 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:51,982 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,121 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  55%|███▊   | 7360/13300 [00:28<00:27, 218.19samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:52,122 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,122 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,125 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,253 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.260:  56%|███▉   | 7392/13300 [00:28<00:26, 225.06samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:52,254 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,254 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,255 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,385 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  56%|███▉   | 7424/13300 [00:29<00:25, 230.08samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:52,386 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,386 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,387 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,528 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  56%|███▉   | 7456/13300 [00:29<00:25, 228.26samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:52,528 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,528 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,530 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,651 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  56%|███▉   | 7488/13300 [00:29<00:24, 237.09samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:52,651 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,651 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,653 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,782 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  57%|███▉   | 7520/13300 [00:29<00:24, 238.79samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:52,783 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,783 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,786 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,923 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  57%|███▉   | 7552/13300 [00:29<00:24, 235.25samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:52,924 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,924 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:52,927 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,056 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  57%|███▉   | 7584/13300 [00:29<00:24, 236.96samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:53,056 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,056 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,058 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,182 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  57%|████   | 7616/13300 [00:29<00:23, 241.48samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:53,183 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,183 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,185 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,302 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  58%|████   | 7648/13300 [00:29<00:22, 248.56samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:53,303 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,303 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,305 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,425 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  58%|████   | 7680/13300 [00:30<00:22, 251.98samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:53,426 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,426 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,427 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,557 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  58%|████   | 7712/13300 [00:30<00:22, 249.34samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:53,557 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,557 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,560 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,694 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  58%|████   | 7744/13300 [00:30<00:22, 244.02samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:53,695 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,695 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,698 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,823 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.258:  58%|████   | 7776/13300 [00:30<00:22, 245.56samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:53,823 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,823 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,825 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,946 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  59%|████   | 7808/13300 [00:30<00:22, 249.51samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:53,947 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,947 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:53,948 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,086 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  59%|████▏  | 7840/13300 [00:30<00:22, 242.76samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:54,087 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,088 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,089 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,214 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 22/22, loss=1.259:  59%|████▏  | 7872/13300 [00:30<00:22, 245.15samples/s]\u001b[1;34m[DEBUG 2017-03-04 18:42:54,215 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,215 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,216 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "^C\n",
      "\n",
      "\u001b[1;31m[ERROR 2017-03-04 18:42:54,451 kur.model.executor:227]\u001b[0m Exception raised during training.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 224, in train\n",
      "    **kwargs\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 586, in wrapped_train\n",
      "    model=self.model, data=batch)\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 822, in try_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/backend/keras_backend.py\", line 725, in train\n",
      "    return self.run_batch(model, data, 'train', True)\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/backend/keras_backend.py\", line 710, in run_batch\n",
      "    outputs = compiled['func'](inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/keras/backend/theano_backend.py\", line 959, in __call__\n",
      "    return self.function(*inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/theano/compile/function_module.py\", line 859, in __call__\n",
      "    outputs = self.fn()\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/theano/scan_module/scan_op.py\", line 951, in rval\n",
      "    r = p(n, [x[0] for x in i], o)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/theano/scan_module/scan_op.py\", line 940, in <lambda>\n",
      "    self, node)\n",
      "KeyboardInterrupt\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 18:42:54,453 kur.model.executor:235]\u001b[0m Saving most recent weights: t2_dp/last.w.kur\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,453 kur.model.model:213]\u001b[0m Saving model weights to: t2_dp/last.w.kur\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,482 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,482 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,483 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,483 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,483 kur.loggers.binary_logger:144]\u001b[0m Writing logger summary.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,485 kur.model.hooks.plot_hook:73]\u001b[0m Plotting hook received training message.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,485 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: batch_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,486 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: batch_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,486 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: batch_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,487 kur.model.hooks.plot_hook:107]\u001b[0m Using per-batch training statistics for plotting.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,487 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,487 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 18:42:54,488 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_time\u001b[0m\n",
      "CPU times: user 1.41 s, sys: 1.55 s, total: 2.97 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kur -vv train char_rrn_demo_dp_fluid.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAG0CAYAAAA7Go31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOiIiIjKx/j/+o/OW24mpUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename='t2_dp/loss.png') \n",
    "# with 15 epochs, the training error is not lower enough. Now we want the model to be overfit a little more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_loss_batch          training_loss_batch       validation_loss_out_char\r\n",
      "batch_loss_out_char       training_loss_out_char    validation_loss_time\r\n",
      "batch_loss_time           training_loss_time        validation_loss_total\r\n",
      "batch_loss_total          training_loss_total\r\n",
      "summary.yml               validation_loss_batch\r\n"
     ]
    }
   ],
   "source": [
    "%ls t2_dp/log/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418.57142857142856"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pycat t2_dp/log/summary.yml\n",
    "# {batches: 8790, epochs: 21, samples: 281028, sessions: 2, version: 2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What summary.yml is tell us?\n",
    "- batches: 8790 == so far we have ran 8790 batches in training????\n",
    "- epochs: 21 == we have ran 21 epochs in traning\n",
    "- samples: 281028 == no idea what it means????\n",
    "- sessions: 2   == no idea what it means???? \n",
    "- version: 2  == no idea what it means????\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-04 15:50:22,384 kur.kurfile:699]\u001b[0m Parsing source: char_rrn_demo_dp_fluid.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:22,387 kur.kurfile:699]\u001b[0m Parsing source: char_rnn_demo_dp_defaults.yaml, included by char_rrn_demo_dp_fluid.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:22,398 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:22,628 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:22,629 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:22,629 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:23,636 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:23,636 kur.model.model:260]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:23,636 kur.model.model:265]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:23,636 kur.model.model:280]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:25,196 kur.model.model:284]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:25,197 kur.model.model:285]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:27,755 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Evaluating: 100%|██████████████████████| 831/831 [00:00<00:00, 1232.05samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:28,482 kur.model.hooks.output_hook:40]\u001b[0m Saving model output as pickle: t2_dp/output.pkl\u001b[0m\n",
      "CPU times: user 132 ms, sys: 140 ms, total: 272 ms\n",
      "Wall time: 7.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kur -v evaluate char_rrn_demo_dp_fluid.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting view_outputs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile view_outputs.py\n",
    "\n",
    "\"\"\"\n",
    "Copyright 2016 Deepgram\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import view_data\n",
    "from vocab import *\n",
    "\n",
    "\n",
    "if len(sys.argv) < 2:\n",
    "    pickle_fname = 't2_dp/output.pkl'\n",
    "else:\n",
    "    pickle_fname = sys.argv[1]\n",
    "\n",
    "with open(pickle_fname, 'rb') as infile:\n",
    "    prediction_data = pickle.load(infile)\n",
    "\n",
    "data = view_data.get_data('evaluate')\n",
    "\n",
    "batch_size = len(prediction_data['truth']['out_char'])\n",
    "\n",
    "for j in range(10):\n",
    "    predicted_char = int_to_char[np.argmax(prediction_data['result']['out_char'][j])]\n",
    "    correct_char = int_to_char[np.argmax(data['out_char'][j])]\n",
    "    print(\n",
    "        '\"%s\" --> \"%s\"' % (\n",
    "            ''.join([\n",
    "                int_to_char[np.argmax(_)]\n",
    "                for _ in data['in_seq'][j]\n",
    "            ]),\n",
    "            predicted_char\n",
    "        )\n",
    "    )\n",
    "    if predicted_char == correct_char:\n",
    "        print((' ' * (seq_len + 5)) + 'CORRECT')\n",
    "    else:\n",
    "        print((' ' * (seq_len + 5)) + 'INCORRECT (%s)' % correct_char)\n",
    "\n",
    "accuracy = sum(\n",
    "    [\n",
    "        int(\n",
    "            np.argmax(prediction_data['result']['out_char'][i]) == np.argmax(prediction_data['truth']['out_char'][i])\n",
    "        )\n",
    "        for i in range(batch_size)\n",
    "    ]\n",
    ") / float(len(prediction_data['truth']['out_char']))\n",
    "\n",
    "print('accuracy = %s' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ng your time with me. mr. bing\" --> \"l\"\r\n",
      "                                   CORRECT\r\n",
      "\"g your time with me. mr. bingl\" --> \"e\"\r\n",
      "                                   CORRECT\r\n",
      "\" your time with me. mr. bingle\" --> \"y\"\r\n",
      "                                   CORRECT\r\n",
      "\"your time with me. mr. bingley\" --> \" \"\r\n",
      "                                   CORRECT\r\n",
      "\"our time with me. mr. bingley \" --> \"w\"\r\n",
      "                                   INCORRECT (f)\r\n",
      "\"ur time with me. mr. bingley f\" --> \"o\"\r\n",
      "                                   CORRECT\r\n",
      "\"r time with me. mr. bingley fo\" --> \"r\"\r\n",
      "                                   INCORRECT (l)\r\n",
      "\" time with me. mr. bingley fol\" --> \"l\"\r\n",
      "                                   CORRECT\r\n",
      "\"time with me. mr. bingley foll\" --> \"o\"\r\n",
      "                                   CORRECT\r\n",
      "\"ime with me. mr. bingley follo\" --> \"w\"\r\n",
      "                                   CORRECT\r\n",
      "accuracy = 0.5054151624548736\r\n"
     ]
    }
   ],
   "source": [
    "!python view_outputs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-04 15:50:38,626 kur.kurfile:699]\u001b[0m Parsing source: char_rrn_demo_dp_fluid.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:38,630 kur.kurfile:699]\u001b[0m Parsing source: char_rnn_demo_dp_defaults.yaml, included by char_rrn_demo_dp_fluid.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:38,641 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:38,967 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:38,967 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:38,967 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:39,538 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:39,538 kur.model.model:260]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:39,538 kur.model.model:265]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:39,539 kur.model.model:280]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:40,342 kur.model.model:284]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:40,342 kur.model.model:285]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:42,728 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Testing, loss=1.700: 100%|█████████████| 831/831 [00:00<00:00, 1246.48samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-04 15:50:43,473 kur.model.executor:197]\u001b[0m Test loss: 1.700\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -v test char_rrn_demo_dp_fluid.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Improvement**\n",
    "- divergence is significantly reduced\n",
    "- gradually converging\n",
    "\n",
    "**Unsatistifed**\n",
    "- original kurfile can achieve loss of 1.65 at epoch 3\n",
    "- dropout version loss is \n",
    "- best loss with dropout version is 1.60 at epoch 12\n",
    "\n",
    "**What more can be done?**\n",
    "- should learning rate can adjusted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Try to write dlnd_character model (tensorflow) in kur\n",
    "1. I am not sure I [understand the model in tensorflow correct](https://hyp.is/DzyoQAChEeeLJ0dOqLuF9A/nbviewer.jupyter.org/github/udacity/deep-learning/blob/master/intro-to-rnns/Anna%20KaRNNa.ipynb). I implemented below anyway, could you verify it for me?\n",
    "- Assume I understand the tensorflow code properly, **does kur's LSTM and dropout operate similarly as Tensorflow's LSTM and dropout**? \n",
    "- In TF's doc, it says its `tf.contrib.rnn.BasicLSTMCell` is built based on [this paper](https://hyp.is/lHmEDACbEeeB_C_Ua4oMgA/arxiv.org/pdf/1409.2329.pdf)\n",
    "- Does Kur automatically implement [gradient clipping](https://hyp.is/ITh66ACqEee3Jd9Zbpvh4A/nbviewer.jupyter.org/github/udacity/deep-learning/blob/master/intro-to-rnns/Anna%20KaRNNa.ipynb) to control gradient explosion as in the tensorflow code? \n",
    "- I don't know how to use `gradient clipping`, so **I assume kur uses it by default**, am I right?\n",
    "- what is the difference between [batch_size and num_step](https://hyp.is/jFlQ5ACrEee6rFuYoSCyqA/nbviewer.jupyter.org/github/udacity/deep-learning/blob/master/intro-to-rnns/Anna%20KaRNNa.ipynb)?\n",
    "- [tips on overfitting and underfitting](https://hyp.is/VavmwgCtEeeLXLcVygsOyw/nbviewer.jupyter.org/github/udacity/deep-learning/blob/master/intro-to-rnns/Anna%20KaRNNa.ipynb) from karpathy post\n",
    "- [tips on balancing data size and model complexity](https://hyp.is/-gOR4gCuEeemKK-35u3Qnw/nbviewer.jupyter.org/github/udacity/deep-learning/blob/master/intro-to-rnns/Anna%20KaRNNa.ipynb)\n",
    "- [how to find the best weights](https://hyp.is/0SE0QACvEeeDd8dKyAHb-w/nbviewer.jupyter.org/github/udacity/deep-learning/blob/master/intro-to-rnns/Anna%20KaRNNa.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dlnd_character model parameter values\n",
    "\n",
    "- batch_size = 100    \n",
    "- num_steps = 100     \n",
    "- lstm_size = 512    \n",
    "- num_layers = 2    \n",
    "- learning_rate = 0.001    \n",
    "- keep_prob = 0.5    \n",
    "\n",
    "**Where can I find information about batch_size of original kur character example**?\n",
    "- `batch_size` is not given in the original kurfile\n",
    "- how do I know the default `batch_size`?\n",
    "\n",
    "**To match dlnd parameters above with kur parameters**\n",
    "```\n",
    "- batch_size           = 100     vs     = 32 for kurfile, found it in `-vv` mode\n",
    "- num_steps            = 100     vs     = 30 = vocab\n",
    "- lstm_size            = 512     vs     = 128 = rnn.size\n",
    "- num_layers           = 2       vs     = 3 = rnn.depth\n",
    "- learning_rate        = 0.001   vs     = unknown in kur?????\n",
    "- keep_prob            = 0.5     vs     = dropout \n",
    "```\n",
    "- no fully connected (fc) layer specified in dlnd_example tensorflow code, does tensorflow automatically add fc_layer?\n",
    "- is fc_layer or dense layer required in RNN model????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting char_rnn_demo_dlnd_defaults.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile char_rnn_demo_dlnd_defaults.yaml\n",
    "\n",
    "---\n",
    "\n",
    "settings:\n",
    "\n",
    "\n",
    "  vocab:                                         # num_steps: unfold the rnn to many steps/sequences  ??????????\n",
    "    size: 30                                     # it cannot be changed to 100, as 30 is set in make_data.py????\n",
    "         # can't set 100 here                    # to set it 100, I have to change 30 to 100 inside make_data.py ??\n",
    "\n",
    "# \"\"\" If set to 100, we get the following error message: \n",
    "# Traceback (most recent call last):\n",
    "#   File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/theano/compile/function_module.py\",\n",
    "# line 859, in __call__\n",
    "#     outputs = self.fn()\n",
    "# ValueError: Input dimension mis-match. (input[0].shape[1] = 100, input[1].shape[1] = 30)\"\"\"        \n",
    "            \n",
    "    \n",
    "# \"\"\"When set to 30, we get the following error meassage: \n",
    "# Traceback (most recent call last):\n",
    "#   File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 224, in train\n",
    "#     **kwargs\n",
    "#   File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 648, in wrapped_train\n",
    "#     raise ValueError('Model loss is NaN.')\n",
    "# ValueError: Model loss is NaN.\n",
    "# \n",
    "# During handling of the above exception, another exception occurred:\n",
    "# \n",
    "# Traceback (most recent call last):\n",
    "#   File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/bin/kur\", line 11, in <module>\n",
    "#     load_entry_point('kur', 'console_scripts', 'kur')()\n",
    "#   File \"/Users/Natsume/Downloads/kur_road/kur/kur/__main__.py\", line 382, in main\n",
    "#     sys.exit(args.func(args) or 0)\n",
    "#   File \"/Users/Natsume/Downloads/kur_road/kur/kur/__main__.py\", line 62, in train\n",
    "#     func(step=args.step)\n",
    "#   File \"/Users/Natsume/Downloads/kur_road/kur/kur/kurfile.py\", line 371, in func\n",
    "#     return trainer.train(**defaults)\n",
    "#   File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 246, in train\n",
    "#     info={'Reason' : reason}\n",
    "#   File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/hooks/plot_hook.py\", line 123, in notify\n",
    "#     vbatch = numpy.arange(1, len(vloss)+1)\n",
    "# TypeError: object of type 'NoneType' has no len()\n",
    "# CPU times: user 511 ms, sys: 504 ms, total: 1.02 s\n",
    "# Wall time: 31.6 s\"\"\"    \n",
    "\n",
    "  rnn:\n",
    "    size: 512                                    # num_neurons of a rnn/lstm layer\n",
    "    depth: 2                                     # num_rnn_layers for this RNN model\n",
    "\n",
    "model:\n",
    "  - input: in_seq\n",
    "\n",
    "\n",
    "  - recurrent:\n",
    "      size: \"{{ rnn.size }}\"\n",
    "      type: lstm\n",
    "      sequence: yes\n",
    "      bidirectional: no\n",
    "  - batch_normalization\n",
    "  - dropout: \"{{drop_neurons}}\"\n",
    "        \n",
    "  - recurrent:\n",
    "      size: \"{{ rnn.size }}\"\n",
    "      type: lstm\n",
    "      sequence: no\n",
    "      bidirectional: no\n",
    "  - batch_normalization\n",
    "  - dropout: \"{{drop_neurons}}\"\n",
    "\n",
    "\n",
    "  - dense: \"{{ vocab.size }}\"                   # is dense a must here?\n",
    "\n",
    "  - activation: softmax\n",
    "\n",
    "  - output: out_char                               # make a name of output layer\n",
    "           \n",
    "\n",
    "loss:\n",
    "  - target: out_char\n",
    "    name: categorical_crossentropy\n",
    "\n",
    "train:\n",
    "  data:\n",
    "    - jsonl: data/train.jsonl\n",
    "  epochs: \"{{ num_epochs|default(5) }}\"     \n",
    "  weights:\n",
    "    initial: t3_dlnd/best.w.kur\n",
    "    best: t3_dlnd/best.w.kur\n",
    "    last: t3_dlnd/last.w.kur\n",
    "  log: t3_dlnd/log\n",
    "  hooks:                                   \n",
    "    - plot: t3_dlnd/loss.png\n",
    "\n",
    "validate:\n",
    "  data:\n",
    "    - jsonl: data/validate.jsonl\n",
    "  weights: t3_dlnd/best.w.kur\n",
    "\n",
    "\n",
    "test:\n",
    "  data:\n",
    "    - jsonl: data/test.jsonl\n",
    "  weights: t3_dlnd/best.w.kur\n",
    "\n",
    "\n",
    "evaluate:\n",
    "  data:\n",
    "    - jsonl: data/evaluate.jsonl\n",
    "  weights: t3_dlnd/best.w.kur\n",
    "\n",
    "  destination: t3_dlnd/output.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting char_rrn_demo_dlnd_fluid.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile char_rrn_demo_dlnd_fluid.yaml\n",
    "\n",
    "---\n",
    "settings: \n",
    "#   num_epochs: 15                    # leave it empty means inf number of epochs\n",
    "                                 # so to use default value, just comment this line out\n",
    "  drop_neurons: 0.5\n",
    "\n",
    "\n",
    "include: char_rnn_demo_dlnd_defaults.yaml\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-04 19:15:25,846 kur.kurfile:699]\u001b[0m Parsing source: char_rrn_demo_dlnd_fluid.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:25,850 kur.kurfile:699]\u001b[0m Parsing source: char_rnn_demo_dlnd_defaults.yaml, included by char_rrn_demo_dlnd_fluid.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:25,861 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,861 kur.kurfile:784]\u001b[0m Parsing Kurfile section: settings\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,861 kur.kurfile:784]\u001b[0m Parsing Kurfile section: train\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,865 kur.kurfile:784]\u001b[0m Parsing Kurfile section: validate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,868 kur.kurfile:784]\u001b[0m Parsing Kurfile section: test\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,870 kur.kurfile:784]\u001b[0m Parsing Kurfile section: evaluate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,873 kur.containers.layers.placeholder:63]\u001b[0m Using short-hand name for placeholder: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,873 kur.containers.layers.placeholder:97]\u001b[0m Placeholder \"in_seq\" has a deferred shape.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,880 kur.containers.layers.output:50]\u001b[0m Using short-hand name for output: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,881 kur.kurfile:784]\u001b[0m Parsing Kurfile section: loss\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:25,883 kur.loggers.binary_logger:71]\u001b[0m Loading log data: t3_dlnd/log\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,883 kur.loggers.binary_logger:158]\u001b[0m Reading logger summary.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,885 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: training_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,885 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/training_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,886 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: training_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,886 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/training_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,886 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: training_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,886 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/training_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,886 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,886 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/validation_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,886 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,887 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/validation_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,887 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:25,887 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/validation_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:29,408 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:29,766 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:29,766 kur.backend.backend:187]\u001b[0m Using backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:29,767 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:29,767 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:29,767 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:29,767 kur.backend.keras_backend:124]\u001b[0m Using the system-default Keras backend.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:29,767 kur.backend.keras_backend:189]\u001b[0m Overriding environmental variables: {'TF_CPP_MIN_LOG_LEVEL': '1', 'KERAS_BACKEND': None, 'THEANO_FLAGS': None}\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:30,935 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:30,935 kur.model.model:260]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:30,935 kur.model.model:265]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,935 kur.model.model:272]\u001b[0m Assembled Node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:274]\u001b[0m   Uses: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:276]\u001b[0m   Used by: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:277]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:272]\u001b[0m Assembled Node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:274]\u001b[0m   Uses: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:276]\u001b[0m   Used by: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:277]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:272]\u001b[0m Assembled Node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:274]\u001b[0m   Uses: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:276]\u001b[0m   Used by: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:277]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:272]\u001b[0m Assembled Node: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:274]\u001b[0m   Uses: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:276]\u001b[0m   Used by: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:277]\u001b[0m   Aliases: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,936 kur.model.model:272]\u001b[0m Assembled Node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:274]\u001b[0m   Uses: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:276]\u001b[0m   Used by: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:277]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:272]\u001b[0m Assembled Node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:274]\u001b[0m   Uses: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:276]\u001b[0m   Used by: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:277]\u001b[0m   Aliases: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:272]\u001b[0m Assembled Node: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:274]\u001b[0m   Uses: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:276]\u001b[0m   Used by: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:277]\u001b[0m   Aliases: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:272]\u001b[0m Assembled Node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:274]\u001b[0m   Uses: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:276]\u001b[0m   Used by: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:277]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:272]\u001b[0m Assembled Node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:274]\u001b[0m   Uses: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,937 kur.model.model:276]\u001b[0m   Used by: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:277]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:272]\u001b[0m Assembled Node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:274]\u001b[0m   Uses: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:276]\u001b[0m   Used by: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:277]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:30,938 kur.model.model:280]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:311]\u001b[0m Building node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:312]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.containers.layers.placeholder:117]\u001b[0m Creating placeholder for \"in_seq\" with data type \"float32\".\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:125]\u001b[0m Trying to infer shape for input \"in_seq\"\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.model.model:143]\u001b[0m Inferred shape for input \"in_seq\": (30, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,938 kur.containers.layers.placeholder:127]\u001b[0m Inferred shape: (30, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,943 kur.model.model:382]\u001b[0m   Value: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,944 kur.model.model:311]\u001b[0m Building node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,944 kur.model.model:312]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,944 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:30,944 kur.model.model:315]\u001b[0m   - in_seq: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,863 kur.model.model:382]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,864 kur.model.model:311]\u001b[0m Building node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,864 kur.model.model:312]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,864 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,864 kur.model.model:315]\u001b[0m   - ..recurrent.0: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,884 kur.model.model:382]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,884 kur.model.model:311]\u001b[0m Building node: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,884 kur.model.model:312]\u001b[0m   Aliases: ..dropout.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,884 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:31,884 kur.model.model:315]\u001b[0m   - ..batch_normalization.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,737 kur.model.model:382]\u001b[0m   Value: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,737 kur.model.model:311]\u001b[0m Building node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,737 kur.model.model:312]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,737 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,738 kur.model.model:315]\u001b[0m   - ..dropout.0: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,880 kur.model.model:382]\u001b[0m   Value: Subtensor{int64}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,880 kur.model.model:311]\u001b[0m Building node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,880 kur.model.model:312]\u001b[0m   Aliases: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,881 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,881 kur.model.model:315]\u001b[0m   - ..recurrent.1: Subtensor{int64}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,889 kur.model.model:382]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,889 kur.model.model:311]\u001b[0m Building node: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,889 kur.model.model:312]\u001b[0m   Aliases: ..dropout.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,889 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,889 kur.model.model:315]\u001b[0m   - ..batch_normalization.1: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,937 kur.model.model:382]\u001b[0m   Value: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,937 kur.model.model:311]\u001b[0m Building node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,937 kur.model.model:312]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,937 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,937 kur.model.model:315]\u001b[0m   - ..dropout.1: if{}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:382]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:311]\u001b[0m Building node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:312]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:315]\u001b[0m   - ..dense.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:382]\u001b[0m   Value: Softmax.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:311]\u001b[0m Building node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:312]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:313]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:315]\u001b[0m   - ..activation.0: Softmax.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,939 kur.model.model:382]\u001b[0m   Value: Softmax.0\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:32,939 kur.model.model:284]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:32,939 kur.model.model:285]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:32,940 kur.kurfile:357]\u001b[0m Ignoring missing initial weights: t3_dlnd/best.w.kur. If this is undesireable, set \"must_exist\" to \"yes\" in the approriate \"weights\" section.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:32,940 kur.model.executor:315]\u001b[0m No historical training loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:32,940 kur.model.executor:323]\u001b[0m No historical validation loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:32,940 kur.model.executor:329]\u001b[0m No previous epochs.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,940 kur.model.executor:353]\u001b[0m Epoch handling mode: additional\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,940 kur.model.executor:101]\u001b[0m Recompiling the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:32,940 kur.backend.keras_backend:527]\u001b[0m Instantiating a Keras model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,774 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,774 kur.backend.keras_backend:538]\u001b[0m Layer (type)                     Output Shape          Param #     Connected to                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,774 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,774 kur.backend.keras_backend:538]\u001b[0m in_seq (InputLayer)              (None, 30, 30)        0                                            \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,775 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,775 kur.backend.keras_backend:538]\u001b[0m ..recurrent.0 (LSTM)             (None, 30, 512)       1112064     in_seq[0][0]                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,775 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,775 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.0 (BatchNo (None, 30, 512)       2048        ..recurrent.0[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,775 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,775 kur.backend.keras_backend:538]\u001b[0m ..dropout.0 (Dropout)            (None, 30, 512)       0           ..batch_normalization.0[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,775 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,775 kur.backend.keras_backend:538]\u001b[0m ..recurrent.1 (LSTM)             (None, 512)           2099200     ..dropout.0[0][0]                \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,776 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,776 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.1 (BatchNo (None, 512)           2048        ..recurrent.1[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,776 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,776 kur.backend.keras_backend:538]\u001b[0m ..dropout.1 (Dropout)            (None, 512)           0           ..batch_normalization.1[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,777 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,777 kur.backend.keras_backend:538]\u001b[0m ..dense.0 (Dense)                (None, 30)            15390       ..dropout.1[0][0]                \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,777 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,777 kur.backend.keras_backend:538]\u001b[0m ..activation.0 (Activation)      (None, 30)            0           ..dense.0[0][0]                  \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,777 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,777 kur.backend.keras_backend:538]\u001b[0m Total params: 3,230,750\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,777 kur.backend.keras_backend:538]\u001b[0m Trainable params: 3,228,702\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,777 kur.backend.keras_backend:538]\u001b[0m Non-trainable params: 2,048\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,778 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,778 kur.backend.keras_backend:538]\u001b[0m \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,778 kur.backend.keras_backend:576]\u001b[0m Assembling a training function from the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:33,785 kur.backend.keras_backend:509]\u001b[0m Adding additional inputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,195 kur.backend.keras_backend:599]\u001b[0m Additional inputs for log functions: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,196 kur.backend.keras_backend:616]\u001b[0m Expected input shapes: in_seq=(None, 30, 30), out_char=(None, None)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,196 kur.backend.keras_backend:634]\u001b[0m Compiled model: {'names': {'output': ['..activation.0', 'out_char'], 'input': ['in_seq', 'out_char']}, 'func': <keras.backend.theano_backend.Function object at 0x11680b978>, 'shapes': {'input': [(None, 30, 30), (None, None)]}}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,196 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,196 kur.providers.batch_provider:102]\u001b[0m Maximum number of batches set to: 1\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:53,242 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,242 kur.providers.batch_provider:139]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,242 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,491 kur.providers.provider:144]\u001b[0m Data source \"in_seq\": entries=13300, shape=(30, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,491 kur.providers.provider:144]\u001b[0m Data source \"out_char\": entries=13300, shape=(30,)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,689 kur.model.hooks.plot_hook:73]\u001b[0m Plotting hook received training message.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,689 kur.model.hooks.plot_hook:80]\u001b[0m Plotting hook does not handle this status.\u001b[0m\n",
      "\n",
      "Epoch 1/5, loss=N/A:   0%|                       | 0/13300 [00:00<?, ?samples/s]\u001b[1;34m[DEBUG 2017-03-04 19:15:53,695 kur.providers.shuffle_provider:184]\u001b[0m Shuffling...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,864 kur.providers.batch_provider:139]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,864 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,864 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,865 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:53,865 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,351 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,351 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,353 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,353 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,354 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,354 kur.loggers.binary_logger:144]\u001b[0m Writing logger summary.\u001b[0m\n",
      "Epoch 1/5, loss=5.298:   0%|            | 32/13300 [00:00<04:33, 48.44samples/s]\u001b[1;34m[DEBUG 2017-03-04 19:15:54,356 kur.model.executor:578]\u001b[0m Training on batch...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,356 kur.providers.batch_provider:156]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,357 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,802 kur.model.executor:597]\u001b[0m Finished training on batch.\u001b[0m\n",
      "Epoch 1/5, loss=nan:   0%|              | 64/13300 [00:01<04:06, 53.66samples/s]\u001b[1;31m[ERROR 2017-03-04 19:15:54,802 kur.model.executor:647]\u001b[0m Received NaN loss value for model output \"out_char\". Make sure that your inputs are all normalized and that the learning rate is not too high. Sometimes different algorithms/implementations work better than others, so you can try switching optimizers or backend.\u001b[0m\n",
      "\n",
      "\u001b[1;31m[ERROR 2017-03-04 19:15:54,802 kur.model.executor:227]\u001b[0m Exception raised during training.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 224, in train\n",
      "    **kwargs\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 648, in wrapped_train\n",
      "    raise ValueError('Model loss is NaN.')\n",
      "ValueError: Model loss is NaN.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-04 19:15:54,803 kur.model.executor:235]\u001b[0m Saving most recent weights: t3_dlnd/last.w.kur\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,803 kur.model.model:213]\u001b[0m Saving model weights to: t3_dlnd/last.w.kur\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,843 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,843 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,843 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,844 kur.loggers.binary_logger:135]\u001b[0m Adding data to binary column: batch_loss_out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,844 kur.loggers.binary_logger:144]\u001b[0m Writing logger summary.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,845 kur.model.hooks.plot_hook:73]\u001b[0m Plotting hook received training message.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,845 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: batch_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,845 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: batch_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,846 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: batch_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,846 kur.model.hooks.plot_hook:107]\u001b[0m Using per-batch training statistics for plotting.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,846 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,846 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/validation_loss_total\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,846 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,846 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/validation_loss_batch\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,846 kur.loggers.binary_logger:184]\u001b[0m Loading binary column: validation_loss_time\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-04 19:15:54,846 kur.loggers.binary_logger:192]\u001b[0m No such log column exists: t3_dlnd/log/validation_loss_time\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 224, in train\n",
      "    **kwargs\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 648, in wrapped_train\n",
      "    raise ValueError('Model loss is NaN.')\n",
      "ValueError: Model loss is NaN.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/bin/kur\", line 11, in <module>\n",
      "    load_entry_point('kur', 'console_scripts', 'kur')()\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/__main__.py\", line 382, in main\n",
      "    sys.exit(args.func(args) or 0)\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/__main__.py\", line 62, in train\n",
      "    func(step=args.step)\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/kurfile.py\", line 371, in func\n",
      "    return trainer.train(**defaults)\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/executor.py\", line 246, in train\n",
      "    info={'Reason' : reason}\n",
      "  File \"/Users/Natsume/Downloads/kur_road/kur/kur/model/hooks/plot_hook.py\", line 123, in notify\n",
      "    vbatch = numpy.arange(1, len(vloss)+1)\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "CPU times: user 511 ms, sys: 504 ms, total: 1.02 s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kur -vv train char_rrn_demo_dlnd_fluid.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
